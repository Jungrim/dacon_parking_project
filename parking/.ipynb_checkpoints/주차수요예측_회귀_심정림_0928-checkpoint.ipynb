{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc387ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "font_path = \"C:/Windows/Fonts/NGULIM.TTF\"\n",
    "font = font_manager.FontProperties(fname=font_path).get_name()\n",
    "rc('font', family=font)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c3446a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "age_gender_df = pd.read_csv('age_gender_info.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7990bb62",
   "metadata": {},
   "source": [
    "## 기본 전처리\n",
    "- 데이콘에서 제시한 오류 2번, 3번 제거\n",
    "- 숫자형 데이터 : 0 으로 결측치 채움\n",
    "- 범주형 데이터 : 같은 단지의 같은 코드로 결측치 채움\n",
    "- 완전히 동일한 중복행 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0af8979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(train_df, test_df):\n",
    "    \n",
    "    # 오류 2번, 3번만 제거 : 1번은 감안하여 분석 하세요!\n",
    "    error_data = error_data = ['C2085', 'C1397', 'C2431', 'C1649', 'C1095', 'C2051', 'C1218', 'C1894', 'C2483', 'C1502', 'C1988']\n",
    "    \n",
    "    for error in error_data :\n",
    "        train_df = train_df[train_df['단지코드'] != error]\n",
    "    \n",
    "    train_df.loc[train_df['임대보증금'] == '-','임대보증금'] = np.nan\n",
    "    train_df.loc[train_df['임대료'] == '-','임대료'] = np.nan\n",
    "\n",
    "    train_df['임대보증금'] = train_df['임대보증금'].astype(float)\n",
    "    train_df['임대료'] = train_df['임대료'].astype(float)\n",
    "    \n",
    "    cols = ['임대보증금', '임대료','도보 10분거리 내 지하철역 수(환승노선 수 반영)','도보 10분거리 내 버스정류장 수']\n",
    "\n",
    "    train_df[cols] = train_df[cols].fillna(0)\n",
    "    test_df[cols] = test_df[cols].fillna(0)\n",
    "    \n",
    "    test_df[ (test_df['단지코드']=='C2411') & (test_df['자격유형'].isnull())] = 'A'\n",
    "    test_df[ (test_df['단지코드']=='C2253') & (test_df['자격유형'].isnull())] = 'C'\n",
    "    \n",
    "    train_df = train_df.drop_duplicates()\n",
    "    test_df = test_df.drop_duplicates()\n",
    "    \n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bae670eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data_preprocessing(train_df, test_df)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_init = train_df.drop('단지코드',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69883994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2556, 14), (949, 14))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_init.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3fafaa",
   "metadata": {},
   "source": [
    "### 범주형 데이터 전처리\n",
    "- 원핫인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e31bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6d9b183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2556, 53)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e41160bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['총세대수', '전용면적', '전용면적별세대수', '공가수', '임대보증금', '임대료',\n",
       "       '도보 10분거리 내 지하철역 수(환승노선 수 반영)', '도보 10분거리 내 버스정류장 수', '단지내주차면수',\n",
       "       '등록차량수', '임대건물구분_상가', '임대건물구분_아파트', '지역_강원도', '지역_경기도', '지역_경상남도',\n",
       "       '지역_경상북도', '지역_광주광역시', '지역_대구광역시', '지역_대전광역시', '지역_부산광역시', '지역_서울특별시',\n",
       "       '지역_세종특별자치시', '지역_울산광역시', '지역_전라남도', '지역_전라북도', '지역_제주특별자치도', '지역_충청남도',\n",
       "       '지역_충청북도', '공급유형_공공분양', '공급유형_공공임대(10년)', '공급유형_공공임대(50년)',\n",
       "       '공급유형_공공임대(5년)', '공급유형_공공임대(분납)', '공급유형_국민임대', '공급유형_영구임대', '공급유형_임대상가',\n",
       "       '공급유형_장기전세', '공급유형_행복주택', '자격유형_A', '자격유형_B', '자격유형_C', '자격유형_D',\n",
       "       '자격유형_E', '자격유형_F', '자격유형_G', '자격유형_H', '자격유형_I', '자격유형_J', '자격유형_K',\n",
       "       '자격유형_L', '자격유형_M', '자격유형_N', '자격유형_O'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns # 임대건물구분, 지역, 공급유형, 자격유형 -> 범주형 변수를 원핫인코딩으로 처리."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79e87c0",
   "metadata": {},
   "source": [
    "### 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ba2c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_target = train['등록차량수']\n",
    "X_data = train.drop('등록차량수',axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07149a12",
   "metadata": {},
   "source": [
    "### LinearRegression 이용한 회귀모델\n",
    "- 평가지표는 대회에서 정한 MAE로 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e01fc4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134.36078705237819\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbceed1",
   "metadata": {},
   "source": [
    "### 교차검증\n",
    "- scoring = 'neg_mean_absolute_error' \n",
    "- 일반적으로 scoring을 값이 클 수록 모델 성능이 좋은 것으로 사이킷런에서 인식하는데,\n",
    "- mae는 값이 클 수록 모델 성능이 저하되는 것이므로 Negative 키워드를 붙여서 사용\n",
    "- 값은 양수로 보기 위해 -1 곱함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59ae8123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[254.46306275 137.83352433 119.121148   174.02640801 246.29458308]\n",
      "186.34774523513798\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "mae_scores = -1 * cross_val_score(lr, X_data, y_target, scoring='neg_mean_absolute_error',cv=5)\n",
    "\n",
    "print(mae_scores)\n",
    "print(np.mean(mae_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c369760b",
   "metadata": {},
   "source": [
    "### 릿지와 라쏘 규제\n",
    "- 회귀계수 값의 차이가 너무 크게 남.\n",
    "- 규제 적용을 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6bdd484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263.06846595 138.66787736 119.42754998 169.25500872 209.83412229]\n",
      "180.05060485963511\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=10)\n",
    "\n",
    "mae_scores = -1 * cross_val_score(ridge, X_data, y_target, scoring='neg_mean_absolute_error',cv=5)\n",
    "\n",
    "print(mae_scores)\n",
    "print(np.mean(mae_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8418c40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[278.52890251 140.1565933  110.83523215 173.35395185 171.25191903]\n",
      "174.82531976977975\n"
     ]
    }
   ],
   "source": [
    "# 회귀계수 값의 차이가 너무 크게 나서,\n",
    "# 규제 적용을 해보자\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=10)\n",
    "\n",
    "mae_scores = -1 * cross_val_score(lasso, X_data, y_target, scoring='neg_mean_absolute_error',cv=5)\n",
    "\n",
    "print(mae_scores)\n",
    "print(np.mean(mae_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1460a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[273.80517017 139.91008926 111.24267413 172.83100692 171.84234941]\n",
      "173.92625797856505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elastic = ElasticNet(alpha=10)\n",
    "\n",
    "mae_scores = -1 * cross_val_score(elastic, X_data, y_target, scoring='neg_mean_absolute_error',cv=5)\n",
    "\n",
    "print(mae_scores)\n",
    "print(np.mean(mae_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10447bc",
   "metadata": {},
   "source": [
    "### 결과\n",
    "- LinearRegression : 186.3\n",
    "- Ridge : 180.0 (alpha=10)\n",
    "- Lasso : 174.8 (alpha=10)\n",
    "- ElasticNet : 173.9 (alpha=10)\n",
    "- (최적의 alpha 값 찾는 것도 후에 고려 필요)\n",
    "\n",
    "**규제만으로는 여전히 에러값이 너무 큼**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cedad",
   "metadata": {},
   "source": [
    "### kfold 검증 함수 생성\n",
    "- log 변환시 교차 검증 후 mae 값이 기존 mae 값과 비교 어려움.\n",
    "- 같은 수치로 비교 하기 위해 kfold 사용\n",
    "- 타깃값의 skew를 제거하기 전과 후 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b5df9d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def kfold_val(n, model, X_data, y_target,expm1):\n",
    "    kfold = KFold(n_splits=n)\n",
    "    cv_mae=[]\n",
    "\n",
    "    n_iter = 0 \n",
    "\n",
    "    for train_index, test_index in kfold.split(X_data):\n",
    "        X_train, X_test = X_data.iloc[train_index], X_data.iloc[test_index]\n",
    "        y_train, y_test = y_target[train_index], y_target[test_index]\n",
    "        # 학습 및 예측\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        n_iter += 1\n",
    "\n",
    "        if expm1 :\n",
    "            y_test = np.expm1(y_test)\n",
    "            y_pred = np.expm1(y_pred)\n",
    "\n",
    "        mae = mean_absolute_error(y_test,y_pred)\n",
    "        train_size = X_train.shape[0]\n",
    "        test_size = X_test.shape[0]\n",
    "#         print('\\n#{0} 교차 검증 MAE :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, mae, train_size, test_size))\n",
    "        cv_mae.append(mae)\n",
    "    # 개별 iteration별 정확도를 합하여 평균 정확도 계산\n",
    "    print(model, '\\n## 평균 검증 MAE:', np.mean(cv_mae))\n",
    "    return np.mean(cv_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa833fbf",
   "metadata": {},
   "source": [
    "## 데이터 변환 (추가 전처리)\n",
    "- 선형 회귀 모델은 피처값과 타깃값의 분포가 정규분포 형태를 매우 선호.\n",
    "- **특히! 타깃값의 경우 왜곡된 형태의 분포도일 경우 예측 성능에 부정적인 영향 미칠 가능성 높음.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d55676",
   "metadata": {},
   "source": [
    "### target 로그변환 + feature 로그변환\n",
    "- 데이터 EDA시, 타깃값 뿐만아니라 피처값들도 오른쪽 꼬리가 긴 skew 가 많이 나타남.\n",
    "- 타깃값과 피처값 모두 로그 변환 후 평가 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "40227d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression() \n",
      "## 평균 검증 MAE: 176.49434423156475\n",
      "Ridge(alpha=10) \n",
      "## 평균 검증 MAE: 149.73366850188603\n",
      "Lasso(alpha=10) \n",
      "## 평균 검증 MAE: 343.9587984146907\n",
      "ElasticNet(alpha=10) \n",
      "## 평균 검증 MAE: 343.9587984146907\n"
     ]
    }
   ],
   "source": [
    "y_target_log = np.log1p(train['등록차량수']) # 타깃에 로그함수 적용\n",
    "X_data_log = np.log1p(X_data)\n",
    "lr_reg = LinearRegression()\n",
    "ridge_reg = Ridge(alpha=10)\n",
    "lasso_reg = Lasso(alpha=10)\n",
    "elastic_reg = ElasticNet(alpha=10)\n",
    "\n",
    "# 성능 평가\n",
    "models = [lr_reg, ridge_reg, lasso_reg, elastic_reg]\n",
    "\n",
    "for model in models:\n",
    "    kfold_val(5, model, X_data_log, y_target_log,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2cc061",
   "metadata": {},
   "source": [
    "### 로그변환(target+feature) 적용 후 Ridge 의 성능이 많이 개선됨.\n",
    "- LinearRegression : 186.3 -> 176.4 \n",
    "- **Ridge : 180.0 (alpha=10) -> 149.7**\n",
    "- Lasso : 174.8 (alpha=10) -> 343.9\n",
    "- ElasticNet : 173.9 (alpha=10) -> 343. 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec7da5",
   "metadata": {},
   "source": [
    "### Ridge, Lasso, Elastic 최적의 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6474c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def get_best_params(model, params,X_data, y_target):\n",
    "    grid_model = GridSearchCV(model, param_grid=params, \n",
    "                              scoring='neg_mean_absolute_error', cv=5)\n",
    "    grid_model.fit(X_data, y_target)\n",
    "    mae = -1 *  grid_model.best_score_\n",
    "    print('{0} 5 CV 시 최적 평균 로그 변환된 MAE 값: {1}, 최적 alpha:{2}'.format(model.__class__.__name__,\n",
    "                                        np.round(mae, 4), grid_model.best_params_))\n",
    "    return grid_model.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2b2d1",
   "metadata": {},
   "source": [
    "- 타깃과 피처 모두 로그 변환된 상태에서 최적의 파라미터 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "31e59792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge 5 CV 시 최적 평균 로그 변환된 MAE 값: 0.2958, 최적 alpha:{'alpha': 5}\n",
      "Lasso 5 CV 시 최적 평균 로그 변환된 MAE 값: 0.3034, 최적 alpha:{'alpha': 0.005}\n",
      "ElasticNet 5 CV 시 최적 평균 로그 변환된 MAE 값: 0.2982, 최적 alpha:{'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "ridge_params = {'alpha' : [0.05,0.1,1,5,8,10,12,15,20]}\n",
    "lasso_params = {'alpha' : [0.001,0.005, 0.008,0.05, 0.03, 0.1, 0.5, 1.5,10]}\n",
    "elastic_params = {'alpha' : [0.001,0.005, 0.008,0.05, 0.03, 0.1, 0.5, 1.5,10]}\n",
    "\n",
    "best_ridge=get_best_params(ridge_reg,ridge_params,X_data_log,y_target_log)\n",
    "best_lasso = get_best_params(lasso_reg,lasso_params,X_data_log,y_target_log)\n",
    "best_elastic = get_best_params(elastic,elastic_params,X_data_log,y_target_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c1b21983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression() \n",
      "## 평균 검증 MAE: 176.49434423156475\n",
      "Ridge(alpha=5) \n",
      "## 평균 검증 MAE: 150.91111135172\n",
      "Lasso(alpha=0.005) \n",
      "## 평균 검증 MAE: 155.49801926244294\n",
      "ElasticNet(alpha=0.001) \n",
      "## 평균 검증 MAE: 152.7007431415346\n"
     ]
    }
   ],
   "source": [
    "lr_reg = LinearRegression()\n",
    "ridge_reg = Ridge(alpha=best_ridge.alpha)\n",
    "lasso_reg = Lasso(alpha=best_lasso.alpha)\n",
    "elastic_reg = ElasticNet(alpha=best_elastic.alpha)\n",
    "\n",
    "# 성능 평가\n",
    "models = [lr_reg, ridge_reg, lasso_reg, elastic_reg]\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    kfold_val(5, model, X_data_log, y_target_log,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d22dd2",
   "metadata": {},
   "source": [
    "\n",
    "### 라쏘와 엘라스틱넷이 최적 파라미터 적용시 성능 개선 많이 됨\n",
    "##### 모델 : 기본전처리 -> 로그변환 -> 최적파라미터\n",
    "- LinearRegression : 186.3    ->       176.4        -> 176.4\n",
    "- Ridge : 180.0 (alpha=5)    ->       149.7        -> 150.9\n",
    "- **Lasso : 174.8 (alpha=0.005)    ->       343.9        -> 155.4**\n",
    "- **ElasticNet : 173.9 (alpha=0.001) ->     343.9        -> 152.7**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9bc933",
   "metadata": {},
   "source": [
    "### 다른 형식으로 데이터 변환\n",
    "\n",
    "- 데이터 스케일링/정규화 작업 필요\n",
    "1. StandardScaler\n",
    "2. MinMaScaler\n",
    "3. log 함수\n",
    "4. 다항 특성 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfbd319",
   "metadata": {},
   "source": [
    "- 타깃값 : log변환적용\n",
    "- 피처값\n",
    "1. 표준정규화\n",
    "2. 표준정규화 + 2차다항\n",
    "3. MinMax \n",
    "4. MinMax + 2차다항\n",
    "5. log변환\n",
    "6. log변환 + 2차다항"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "14df53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "def get_scaled_data(method='None', p_degree=None, input_data=None):\n",
    "    if method == 'Standard':\n",
    "        scaled_data = StandardScaler().fit_transform(input_data)\n",
    "    elif method =='MinMax':\n",
    "        scaled_data = MinMaxScaler().fit_transform(input_data)\n",
    "    elif method == 'Log':\n",
    "        scaled_data = np.log1p(input_data)\n",
    "    else:\n",
    "        scaled_data = input_data\n",
    "    \n",
    "    \n",
    "    if p_degree != None:\n",
    "        scaled_data = PolynomialFeatures(degree=p_degree, include_bias=False).fit_transform(scaled_data)\n",
    "    \n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c702fa42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard + None\n",
      "Ridge 5 CV 시 최적 평균 로그 변환된 MAE 값: 0.3416, 최적 alpha:{'alpha': 20}\n",
      "Lasso 5 CV 시 최적 평균 로그 변환된 MAE 값: 0.3544, 최적 alpha:{'alpha': 0.001}\n",
      "ElasticNet 5 CV 시 최적 평균 로그 변환된 MAE 값: 0.3524, 최적 alpha:{'alpha': 0.001}\n",
      "            0         1         2         3         4         5         6   \\\n",
      "0    -0.633589 -0.374801  1.183161  0.350280 -0.670450 -0.638592 -0.372238   \n",
      "1    -0.633589 -0.188008 -0.400902  0.350280 -0.499466 -0.456947 -0.372238   \n",
      "2    -0.633589 -0.188008 -0.694247  0.350280 -0.499466 -0.456947 -0.372238   \n",
      "3    -0.633589  0.034800 -0.562242  0.350280 -0.214445 -0.136836 -0.372238   \n",
      "4    -0.633589  0.034800 -0.701580  0.350280 -0.214445 -0.136836 -0.372238   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "2551 -1.261341  0.105000 -0.701580 -0.602385 -0.565069 -0.389666 -0.372238   \n",
      "2552 -1.261341  0.162381 -0.591576 -0.602385 -0.433517 -0.192779 -0.372238   \n",
      "2553 -1.261341  0.182220 -0.591576 -0.602385 -0.433517 -0.192779 -0.372238   \n",
      "2554 -1.261341  0.189240 -0.004886 -0.602385 -0.433517 -0.192779 -0.372238   \n",
      "2555 -1.261341  0.280500 -0.701580 -0.602385 -0.392701 -0.127300 -0.372238   \n",
      "\n",
      "            7         8         9   ...       42        43        44  \\\n",
      "0    -0.257620 -0.010321 -0.354253  ... -0.03428 -0.059444 -0.253206   \n",
      "1    -0.257620 -0.010321 -0.354253  ... -0.03428 -0.059444 -0.253206   \n",
      "2    -0.257620 -0.010321 -0.354253  ... -0.03428 -0.059444 -0.253206   \n",
      "3    -0.257620 -0.010321 -0.354253  ... -0.03428 -0.059444 -0.253206   \n",
      "4    -0.257620 -0.010321 -0.354253  ... -0.03428 -0.059444 -0.253206   \n",
      "...        ...       ...       ...  ...      ...       ...       ...   \n",
      "2551 -0.993761 -1.185600 -0.354253  ... -0.03428 -0.059444 -0.253206   \n",
      "2552 -0.993761 -1.185600 -0.354253  ... -0.03428 -0.059444 -0.253206   \n",
      "2553 -0.993761 -1.185600 -0.354253  ... -0.03428 -0.059444 -0.253206   \n",
      "2554 -0.993761 -1.185600 -0.354253  ... -0.03428 -0.059444 -0.253206   \n",
      "2555 -0.993761 -1.185600 -0.354253  ... -0.03428 -0.059444 -0.253206   \n",
      "\n",
      "            45        46        47        48        49        50        51  \n",
      "0    -0.139804 -0.195398 -0.114366 -0.114366 -0.027984 -0.107126 -0.019784  \n",
      "1    -0.139804 -0.195398 -0.114366 -0.114366 -0.027984 -0.107126 -0.019784  \n",
      "2    -0.139804 -0.195398 -0.114366 -0.114366 -0.027984 -0.107126 -0.019784  \n",
      "3    -0.139804 -0.195398 -0.114366 -0.114366 -0.027984 -0.107126 -0.019784  \n",
      "4    -0.139804 -0.195398 -0.114366 -0.114366 -0.027984 -0.107126 -0.019784  \n",
      "...        ...       ...       ...       ...       ...       ...       ...  \n",
      "2551 -0.139804 -0.195398 -0.114366 -0.114366 -0.027984 -0.107126 -0.019784  \n",
      "2552 -0.139804 -0.195398 -0.114366 -0.114366 -0.027984 -0.107126 -0.019784  \n",
      "2553 -0.139804 -0.195398 -0.114366 -0.114366 -0.027984 -0.107126 -0.019784  \n",
      "2554 -0.139804 -0.195398 -0.114366 -0.114366 -0.027984 -0.107126 -0.019784  \n",
      "2555 -0.139804 -0.195398 -0.114366 -0.114366 -0.027984 -0.107126 -0.019784  \n",
      "\n",
      "[2556 rows x 52 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [136]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_scaled_df)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m---> 31\u001b[0m     \u001b[43mkfold_val\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_scaled_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_target_log\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [120]\u001b[0m, in \u001b[0;36mkfold_val\u001b[1;34m(n, model, X_data, y_target, expm1)\u001b[0m\n\u001b[0;32m     19\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(y_test)\n\u001b[0;32m     20\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpm1(y_pred)\n\u001b[1;32m---> 22\u001b[0m mae \u001b[38;5;241m=\u001b[39m \u001b[43mmean_absolute_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m train_size \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     24\u001b[0m test_size \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:191\u001b[0m, in \u001b[0;36mmean_absolute_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_absolute_error\u001b[39m(\n\u001b[0;32m    136\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;124;03m\"\"\"Mean absolute error regression loss.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_absolute_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    0.85...\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    195\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39mabs(y_pred \u001b[38;5;241m-\u001b[39m y_true), weights\u001b[38;5;241m=\u001b[39msample_weight, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:96\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m     95\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m---> 96\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     99\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    797\u001b[0m         )\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 800\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    108\u001b[0m         allow_nan\n\u001b[0;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m    112\u001b[0m     ):\n\u001b[0;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    117\u001b[0m             )\n\u001b[0;32m    118\u001b[0m         )\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# scale_methods=[ ('Standard', None), ('Standard', 2), \n",
    "#                ('MinMax', None), ('MinMax', 2), ('Log', None), ('Log', 2)]\n",
    "\n",
    "scale_methods=[ ('Standard', None)]\n",
    "\n",
    "for s in scale_methods:\n",
    "\n",
    "    X_scaled_data = get_scaled_data(method=s[0], p_degree=s[1], input_data=X_data)\n",
    "    print(s[0], '+', s[1])\n",
    "\n",
    "    X_scaled_df = pd.DataFrame(X_scaled_data)\n",
    "\n",
    "    ridge_params = {'alpha' : [0.05,0.1,1,5,8,10,12,15,20]}\n",
    "    lasso_params = {'alpha' : [0.001,0.005, 0.008,0.05, 0.03, 0.1, 0.5, 1.5,10]}\n",
    "    elastic_params = {'alpha' : [0.001,0.005, 0.008,0.05, 0.03, 0.1, 0.5, 1.5,10]}\n",
    "\n",
    "    best_ridge=get_best_params(ridge_reg,ridge_params,X_scaled_data,y_target_log)\n",
    "    best_lasso = get_best_params(lasso_reg,lasso_params,X_scaled_data,y_target_log)\n",
    "    best_elastic = get_best_params(elastic,elastic_params,X_scaled_data,y_target_log)\n",
    "    \n",
    "    lr_reg = LinearRegression()\n",
    "    ridge_reg = Ridge(alpha=best_ridge.alpha)\n",
    "    lasso_reg = Lasso(alpha=best_lasso.alpha)\n",
    "    elastic_reg = ElasticNet(alpha=best_elastic.alpha)\n",
    "\n",
    "    # 성능 평가\n",
    "    models = [lr_reg, ridge_reg, lasso_reg, elastic_reg]\n",
    "#     print(y_target_log)\n",
    "#     print(X_scaled_df)\n",
    "    for model in models:\n",
    "        kfold_val(5, model, X_scaled_df, y_target_log,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e02de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fcb47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
